{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClassHW 3/6/20.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP20oGDNmS81w3I144BTpzV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nineMAN9/mh429-is465-/blob/master/ClassHW_3_6_20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4ll_5pwK3aD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "efc80af0-6ebb-46a6-d2cd-a6aa3eb16d87"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        " \n",
        "from nltk.corpus import wordnet\n",
        "syns = wordnet.synsets(\"dog\")\n",
        "print(syns)\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "synonyms = []\n",
        "antonyms = []\n",
        "\n",
        "for syn in wordnet.synsets(\"active\"):\n",
        "\t\tfor l in syn.lemmas():\n",
        "\t\t\tsynonyms.append(l.name())\n",
        "\t\t\tif l.antonyms():\n",
        "\t\t\t\t antonyms.append(l.antonyms()[0].name())\n",
        "\n",
        "print(set(synonyms))\n",
        "print(set(antonyms))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[Synset('dog.n.01'), Synset('frump.n.01'), Synset('dog.n.03'), Synset('cad.n.01'), Synset('frank.n.02'), Synset('pawl.n.01'), Synset('andiron.n.01'), Synset('chase.v.01')]\n",
            "{'active_agent', 'fighting', 'combat-ready', 'alive', 'active', 'dynamic', 'active_voice', 'participating'}\n",
            "{'stative', 'quiet', 'extinct', 'dormant', 'passive', 'inactive', 'passive_voice'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_DQRJzAORjD",
        "colab_type": "text"
      },
      "source": [
        "Explanation of the code\n",
        "\n",
        "Wordnet is a corpus, so it is imported from the ntlk.corpus List of both synonym and antonym is taken as empty which will be used for appending Synonyms of the word active are searched in the module synsets and are appended in the list synonyms. The same process is repeated for the second one. Output is printed Conclusion:\n",
        "\n",
        "WordNet is a lexical database that has been used by a major search engine. From the WordNet, information about a given word or phrase can be calculated such as\n",
        "\n",
        "synonym (words having the same meaning) hypernyms (The generic term used to designate a class of specifics (i.e., meal is a breakfast), hyponyms (rice is a meal) holonyms (proteins, carbohydrates are part of meal) meronyms (meal is part of daily food intake) WordNet also provides information on co-ordinate terms, derivates, senses and more. It is used to find the similarities between any two words. It also holds information on the results of the related word. In short or nutshell one can treat it as Dictionary or Thesaurus. Going deeper in wordnet, it is divided into four total subnets such as\n",
        "\n",
        "Noun Verb Adjective Adverb It can be used in the area of artificial intelligence for text analysis. With the help of Wordnet, you can create your corpus for spelling checking, language translation, Spam detection and many more.\n",
        "\n",
        "In the same way, you can use this corpus and mold it to work some dynamic functionality. This is just like ready to made corpus for you. You can use it in your way."
      ]
    }
  ]
}