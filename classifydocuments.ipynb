{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classifydocuments.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOwgdSnRu8i8NKRMrmwW7sp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nineMAN9/mh429-is465-/blob/master/classifydocuments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZshRGWoT83zB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "3bbcbe61-ee15-477c-f11a-0f6cdcd2d774"
      },
      "source": [
        "{\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 0,\n",
        "  \"metadata\": {\n",
        "    \"colab\": {\n",
        "      \"name\": \"Document Classification.ipynb\",\n",
        "      \"provenance\": [],\n",
        "      \"include_colab_link\": true\n",
        "    },\n",
        "    \"kernelspec\": {\n",
        "      \"name\": \"python3\",\n",
        "      \"display_name\": \"Python 3\"\n",
        "    }\n",
        "  },\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"view-in-github\",\n",
        "        \"colab_type\": \"text\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"<a href=\\\"https://github.com/nineMAN9/mh429-is465-/blob/master/classifydocuments\" target=\\\"_parent\\\"><img src=\\\"https://colab.research.google.com/assets/colab-badge.svg\\\" alt=\\\"Open In Colab\\\"/></a>\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"RJ9M9H7cG99X\",\n",
        "        \"colab_type\": \"code\",\n",
        "        \"outputId\": \"dd3ec626-8bf9-4b7e-cc02-c60c27ce9cab\",\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 33\n",
        "        }\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"print('hello world')\"\n",
        "      ],\n",
        "      \"execution_count\": 0,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"text\": [\n",
        "            \"hello world\\n\"\n",
        "          ],\n",
        "          \"name\": \"stdout\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"uyK9R3aSOrDQ\",\n",
        "        \"colab_type\": \"text\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"Start\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"2kprkhf1HhZA\",\n",
        "        \"colab_type\": \"code\",\n",
        "        \"colab\": {}\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Author: Olivier Grisel <olivier.grisel@ensta.org>\\n\",\n",
        "        \"#         Lars Buitinck\\n\",\n",
        "        \"#         Chyi-Kwei Yau <chyikwei.yau@gmail.com>\\n\",\n",
        "        \"# License: BSD 3 clause\\n\"\n",
        "      ],\n",
        "      \"execution_count\": 0,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"UX307rXJHrTD\",\n",
        "        \"colab_type\": \"text\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"import some packages: time is python time \\n\",\n",
        "        \"\\n\",\n",
        "        \"web mining is mining the text\\n\",\n",
        "        \"web mining is fun\\n\",\n",
        "        \"I like this class\\n\",\n",
        "        \"idf log3/2\\n\",\n",
        "        \"tf-idf 1/6*log3/2\\n\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"Ye90Rd_JIYm2\",\n",
        "        \"colab_type\": \"code\",\n",
        "        \"colab\": {}\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"from time import time\\n\",\n",
        "        \"\\n\",\n",
        "        \"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\\n\",\n",
        "        \"from sklearn.decomposition import NMF, LatentDirichletAllocation\\n\",\n",
        "        \"from sklearn.datasets import fetch_20newsgroups\"\n",
        "      ],\n",
        "      \"execution_count\": 0,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"rU0xULmiKKIq\",\n",
        "        \"colab_type\": \"text\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"Define some variables \"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"DLJv0YT4KOxX\",\n",
        "        \"colab_type\": \"code\",\n",
        "        \"outputId\": \"6a9c8b0a-f8df-4209-be22-548352fd614c\",\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 33\n",
        "        }\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"n_samples = 2000\\n\",\n",
        "        \"n_features = 1000\\n\",\n",
        "        \"n_components = 10\\n\",\n",
        "        \"n_top_words = 20\\n\",\n",
        "        \"print(n_samples)\"\n",
        "      ],\n",
        "      \"execution_count\": 0,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"text\": [\n",
        "            \"2000\\n\"\n",
        "          ],\n",
        "          \"name\": \"stdout\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"kGm4eNacKk4J\",\n",
        "        \"colab_type\": \"text\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"Define function\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"bFPFisMbKmvA\",\n",
        "        \"colab_type\": \"code\",\n",
        "        \"colab\": {}\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"def print_top_words(model, feature_names, n_top_words):\\n\",\n",
        "        \"    for topic_idx, topic in enumerate(model.components_):\\n\",\n",
        "        \"        message = \\\"Topic #%d: \\\" % topic_idx\\n\",\n",
        "        \"        message += \\\" \\\".join([feature_names[i]\\n\",\n",
        "        \"                             for i in topic.argsort()[:-n_top_words - 1:-1]])\\n\",\n",
        "        \"        print(message)\\n\",\n",
        "        \"    print()\"\n",
        "      ],\n",
        "      \"execution_count\": 0,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"nCOi9Gc9K9QU\",\n",
        "        \"colab_type\": \"text\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"# Load the 20 newsgroups dataset and vectorize it. We use a few heuristics\\n\",\n",
        "        \"# to filter out useless terms early on: the posts are stripped of headers,\\n\",\n",
        "        \"# footers and quoted replies, and common English words, words occurring in\\n\",\n",
        "        \"# only one document or in at least 95% of the documents are removed.\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"PWjs_4u4LOT7\",\n",
        "        \"colab_type\": \"code\",\n",
        "        \"outputId\": \"360229a2-a867-4225-c357-b79f4fff885a\",\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 50\n",
        "        }\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"print(\\\"Loading dataset...\\\")\\n\",\n",
        "        \"t0 = time()\\n\",\n",
        "        \"data, _ = fetch_20newsgroups(shuffle=True, random_state=1,\\n\",\n",
        "        \"                             remove=('headers', 'footers', 'quotes'),\\n\",\n",
        "        \"                             return_X_y=True)\\n\",\n",
        "        \"data_samples = data[:n_samples]\\n\",\n",
        "        \"print(\\\"done in %0.3fs.\\\" % (time() - t0))\"\n",
        "      ],\n",
        "      \"execution_count\": 0,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"text\": [\n",
        "            \"Loading dataset...\\n\",\n",
        "            \"done in 1.444s.\\n\"\n",
        "          ],\n",
        "          \"name\": \"stdout\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"3TB5ty8PLsFg\",\n",
        "        \"colab_type\": \"text\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"# Use tf-idf features for NMF.\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"wNryVPxrLxYv\",\n",
        "        \"colab_type\": \"code\",\n",
        "        \"outputId\": \"a7d876b2-cbbb-4d15-bd25-510dff76a35f\",\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 50\n",
        "        }\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"print(\\\"Extracting tf-idf features for NMF...\\\")\\n\",\n",
        "        \"tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\\n\",\n",
        "        \"                                   max_features=n_features,\\n\",\n",
        "        \"                                   stop_words='english')\\n\",\n",
        "        \"t0 = time()\\n\",\n",
        "        \"tfidf = tfidf_vectorizer.fit_transform(data_samples)\\n\",\n",
        "        \"print(\\\"done in %0.3fs.\\\" % (time() - t0))\"\n",
        "      ],\n",
        "      \"execution_count\": 0,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"text\": [\n",
        "            \"Extracting tf-idf features for NMF...\\n\",\n",
        "            \"done in 0.363s.\\n\"\n",
        "          ],\n",
        "          \"name\": \"stdout\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"-gUH-fM-MDL_\",\n",
        "        \"colab_type\": \"text\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"# Use tf (raw term count) features for LDA.\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"iUMvwNYQMG-I\",\n",
        "        \"colab_type\": \"code\",\n",
        "        \"outputId\": \"ec88bc21-2efa-4a8c-f5af-a151d4852b11\",\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 67\n",
        "        }\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"print(\\\"Extracting tf features for LDA...\\\")\\n\",\n",
        "        \"tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\\n\",\n",
        "        \"                                max_features=n_features,\\n\",\n",
        "        \"                                stop_words='english')\\n\",\n",
        "        \"t0 = time()\\n\",\n",
        "        \"tf = tf_vectorizer.fit_transform(data_samples)\\n\",\n",
        "        \"print(\\\"done in %0.3fs.\\\" % (time() - t0))\\n\",\n",
        "        \"print()\"\n",
        "      ],\n",
        "      \"execution_count\": 0,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"text\": [\n",
        "            \"Extracting tf features for LDA...\\n\",\n",
        "            \"done in 0.362s.\\n\",\n",
        "            \"\\n\"\n",
        "          ],\n",
        "          \"name\": \"stdout\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"QVGGQs2XMQoD\",\n",
        "        \"colab_type\": \"text\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"# Fit the NMF model\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"ZYYfShQ-MS3z\",\n",
        "        \"colab_type\": \"code\",\n",
        "        \"outputId\": \"99ecf7ab-320c-4c20-f6bd-33657eb47361\",\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 268\n",
        "        }\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"print(\\\"Fitting the NMF model (Frobenius norm) with tf-idf features, \\\"\\n\",\n",
        "        \"      \\\"n_samples=%d and n_features=%d...\\\"\\n\",\n",
        "        \"      % (n_samples, n_features))\\n\",\n",
        "        \"t0 = time()\\n\",\n",
        "        \"nmf = NMF(n_components=n_components, random_state=1,\\n\",\n",
        "        \"          alpha=.1, l1_ratio=.5).fit(tfidf)\\n\",\n",
        "        \"print(\\\"done in %0.3fs.\\\" % (time() - t0))\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"\\\\nTopics in NMF model (Frobenius norm):\\\")\\n\",\n",
        "        \"tfidf_feature_names = tfidf_vectorizer.get_feature_names()\\n\",\n",
        "        \"print_top_words(nmf, tfidf_feature_names, n_top_words)\"\n",
        "      ],\n",
        "      \"execution_count\": 0,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"text\": [\n",
        "            \"Fitting the NMF model (Frobenius norm) with tf-idf features, n_samples=2000 and n_features=1000...\\n\",\n",
        "            \"done in 0.379s.\\n\",\n",
        "            \"\\n\",\n",
        "            \"Topics in NMF model (Frobenius norm):\\n\",\n",
        "            \"Topic #0: just people don think like know time good make way really say right ve want did ll new use years\\n\",\n",
        "            \"Topic #1: windows use dos using window program os drivers application help software pc running ms screen files version card code work\\n\",\n",
        "            \"Topic #2: god jesus bible faith christian christ christians does heaven sin believe lord life church mary atheism belief human love religion\\n\",\n",
        "            \"Topic #3: thanks know does mail advance hi info interested email anybody looking card help like appreciated information send list video need\\n\",\n",
        "            \"Topic #4: car cars tires miles 00 new engine insurance price condition oil power speed good 000 brake year models used bought\\n\",\n",
        "            \"Topic #5: edu soon com send university internet mit ftp mail cc pub article information hope program mac email home contact blood\\n\",\n",
        "            \"Topic #6: file problem files format win sound ftp pub read save site help image available create copy running memory self version\\n\",\n",
        "            \"Topic #7: game team games year win play season players nhl runs goal hockey toronto division flyers player defense leafs bad teams\\n\",\n",
        "            \"Topic #8: drive drives hard disk floppy software card mac computer power scsi controller apple mb 00 pc rom sale problem internal\\n\",\n",
        "            \"Topic #9: key chip clipper keys encryption government public use secure enforcement phone nsa communications law encrypted security clinton used legal standard\\n\",\n",
        "            \"\\n\"\n",
        "          ],\n",
        "          \"name\": \"stdout\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"i9mcpvOKNT7m\",\n",
        "        \"colab_type\": \"text\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"# Fit the NMF model\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"4oVsBWEoNXKF\",\n",
        "        \"colab_type\": \"code\",\n",
        "        \"outputId\": \"f9572517-4b0c-43ac-a2c0-874535a54172\",\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 268\n",
        "        }\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"print(\\\"Fitting the NMF model (generalized Kullback-Leibler divergence) with \\\"\\n\",\n",
        "        \"      \\\"tf-idf features, n_samples=%d and n_features=%d...\\\"\\n\",\n",
        "        \"      % (n_samples, n_features))\\n\",\n",
        "        \"t0 = time()\\n\",\n",
        "        \"nmf = NMF(n_components=n_components, random_state=1,\\n\",\n",
        "        \"          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\\n\",\n",
        "        \"          l1_ratio=.5).fit(tfidf)\\n\",\n",
        "        \"print(\\\"done in %0.3fs.\\\" % (time() - t0))\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"\\\\nTopics in NMF model (generalized Kullback-Leibler divergence):\\\")\\n\",\n",
        "        \"tfidf_feature_names = tfidf_vectorizer.get_feature_names()\\n\",\n",
        "        \"print_top_words(nmf, tfidf_feature_names, n_top_words)\\n\",\n",
        "        \"\\n\"\n",
        "      ],\n",
        "      \"execution_count\": 0,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"text\": [\n",
        "            \"Fitting the NMF model (generalized Kullback-Leibler divergence) with tf-idf features, n_samples=2000 and n_features=1000...\\n\",\n",
        "            \"done in 1.507s.\\n\",\n",
        "            \"\\n\",\n",
        "            \"Topics in NMF model (generalized Kullback-Leibler divergence):\\n\",\n",
        "            \"Topic #0: people don just like think did say time make know really right said things way ve course didn question probably\\n\",\n",
        "            \"Topic #1: windows help thanks using hi looking info video dos pc does anybody ftp appreciated mail know advance available use card\\n\",\n",
        "            \"Topic #2: god does jesus true book christian bible christians religion faith believe life church christ says know read exist lord people\\n\",\n",
        "            \"Topic #3: thanks know bike interested mail like new car edu heard just price list email hear want cars thing sounds reply\\n\",\n",
        "            \"Topic #4: 10 00 sale time power 12 new 15 year 30 offer condition 14 16 model 11 monitor 100 old 25\\n\",\n",
        "            \"Topic #5: space government number public data states earth security water research nasa general 1993 phone information science technology provide blood internet\\n\",\n",
        "            \"Topic #6: edu file com program soon try window problem remember files sun send library article mike wrong think code win manager\\n\",\n",
        "            \"Topic #7: game team year games play win season points world division won players nhl flyers toronto case cubs teams ll record\\n\",\n",
        "            \"Topic #8: drive think hard software disk drives apple computer mac need scsi card don problem read floppy post cable going ii\\n\",\n",
        "            \"Topic #9: use good just key chip got like ll way clipper doesn keys don better speed stuff want sure going need\\n\",\n",
        "            \"\\n\"\n",
        "          ],\n",
        "          \"name\": \"stdout\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"dzpfrgimOTWe\",\n",
        "        \"colab_type\": \"text\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"LDA Models\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"fPSzvrP4OUOG\",\n",
        "        \"colab_type\": \"code\",\n",
        "        \"outputId\": \"f619bb3b-6824-4b15-a251-471e2b24ca4e\",\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 268\n",
        "        }\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"print(\\\"Fitting LDA models with tf features, \\\"\\n\",\n",
        "        \"      \\\"n_samples=%d and n_features=%d...\\\"\\n\",\n",
        "        \"      % (n_samples, n_features))\\n\",\n",
        "        \"lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\\n\",\n",
        "        \"                                learning_method='online',\\n\",\n",
        "        \"                                learning_offset=50.,\\n\",\n",
        "        \"                                random_state=0)\\n\",\n",
        "        \"t0 = time()\\n\",\n",
        "        \"lda.fit(tf)\\n\",\n",
        "        \"print(\\\"done in %0.3fs.\\\" % (time() - t0))\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"\\\\nTopics in LDA model:\\\")\\n\",\n",
        "        \"tf_feature_names = tf_vectorizer.get_feature_names()\\n\",\n",
        "        \"print_top_words(lda, tf_feature_names, n_top_words)\"\n",
        "      ],\n",
        "      \"execution_count\": 0,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"text\": [\n",
        "            \"Fitting LDA models with tf features, n_samples=2000 and n_features=1000...\\n\",\n",
        "            \"done in 4.427s.\\n\",\n",
        "            \"\\n\",\n",
        "            \"Topics in LDA model:\\n\",\n",
        "            \"Topic #0: edu com mail send graphics ftp pub available contact university list faq ca information cs 1993 program sun uk mit\\n\",\n",
        "            \"Topic #1: don like just know think ve way use right good going make sure ll point got need really time doesn\\n\",\n",
        "            \"Topic #2: christian think atheism faith pittsburgh new bible radio games alt lot just religion like book read play time subject believe\\n\",\n",
        "            \"Topic #3: drive disk windows thanks use card drives hard version pc software file using scsi help does new dos controller 16\\n\",\n",
        "            \"Topic #4: hiv health aids disease april medical care research 1993 light information study national service test led 10 page new drug\\n\",\n",
        "            \"Topic #5: god people does just good don jesus say israel way life know true fact time law want believe make think\\n\",\n",
        "            \"Topic #6: 55 10 11 18 15 team game 19 period play 23 12 13 flyers 20 25 22 17 24 16\\n\",\n",
        "            \"Topic #7: car year just cars new engine like bike good oil insurance better tires 000 thing speed model brake driving performance\\n\",\n",
        "            \"Topic #8: people said did just didn know time like went think children came come don took years say dead told started\\n\",\n",
        "            \"Topic #9: key space law government public use encryption earth section security moon probe enforcement keys states lunar military crime surface technology\\n\",\n",
        "            \"\\n\"\n",
        "          ],\n",
        "          \"name\": \"stdout\"\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "} "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-5f6e4e89707b>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    \"<a href=\\\"https://github.com/nineMAN9/mh429-is465-/blob/master/classifydocuments\" target=\\\"_parent\\\"><img src=\\\"https://colab.research.google.com/assets/colab-badge.svg\\\" alt=\\\"Open In Colab\\\"/></a>\"\u001b[0m\n\u001b[0m                                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}